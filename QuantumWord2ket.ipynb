{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "6e7f00c6-0fba-415c-e8ae-b024f4200dc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (4.66.1)\n",
            "Requirement already satisfied: requests in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.31.0)\n",
            "Requirement already satisfied: torch==2.2.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (2.2.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (1.24.3)\n",
            "Requirement already satisfied: torchdata==0.7.1 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.0->torchtext) (2023.12.2)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchdata==0.7.1->torchtext) (2.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torchtext) (2023.11.17)\n",
            "Requirement already satisfied: colorama in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.2.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.2.0->torchtext) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "#!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "bb3f74ca-10aa-4215-8501-4a297fbc01cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "0c39e30a-52dd-42b0-9924-b513b5a55397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "    \n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()), batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()),batch_size=128)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "8378145f-943c-440c-b1a6-e6bc4ad80aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "3657        3657  this Earth that is my Muse had slept. Give me ...     True\n",
            "2883        2883  within his hand Against Mamá s swart devils we...     True\n",
            "1494        1494  So masterfully rude Wasting of ancient than pl...     True\n",
            "2410        2410  and nibble the lettuce has grown deep like the...     True\n",
            "4583        4583  Surfaces serve their own purposes, strive to r...    False\n",
            "...          ...                                                ...      ...\n",
            "3825        3825  We have walked in Love's land a little way, We...    False\n",
            "740          740  his home my father did. Ask us not. I don t kn...     True\n",
            "1731        1731  is where those frozen. On a crosshatch of my s...     True\n",
            "1026        1026  With only his dim lantern    To tell him where...    False\n",
            "246          246  When in the chronicle of wasted time I see des...    False\n",
            "\n",
            "[959 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "3823        3823  The food is on the table. Turkey tanned to a c...    False\n",
            "3332        3332  action they pinned a when I. Gathering murk. A...     True\n",
            "3079        3079  A flower into wilting telescopes. I shall comm...     True\n",
            "2826        2826  and took insidethe Archaeological Museum On th...     True\n",
            "1650        1650  his returne that seemes to scorne Base thing. ...     True\n",
            "...          ...                                                ...      ...\n",
            "4787        4787  O but we talked at large before The sixteen me...    False\n",
            "2159        2159  Lying in bed and waiting to find out Whatever ...    False\n",
            "504          504  What is skin, if not a taut swaddle loosening,...    False\n",
            "1986        1986  winds arise and go. For I. Anthony oil Lourdes...     True\n",
            "3880        3880  hand. To try. Then fancy s eye. Not even the c...     True\n",
            "\n",
            "[3835 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n"
          ]
        }
      ],
      "source": [
        "def bitwise_input(input,n_max = 16):  \n",
        "    bits = []\n",
        "    for i in bin(input)[2:]:\n",
        "        bits.append(int(i))\n",
        "    # filling\n",
        "    for _ in range(n_max - len(bits)):\n",
        "        bits.insert(0,0)\n",
        "    return bits[:n_max]\n",
        "\n",
        "print(bitwise_input(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getProb(prob,nmax = 16):\n",
        "    out = []\n",
        "    for i in range(nmax):\n",
        "        out.append(prob[2**nmax-1])\n",
        "    print(out)\n",
        "    return out\n",
        "        \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quantum Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    #inp = bitwise_input(inputs,n_qubits)\n",
        "    #print(inputs)\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires = i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
            "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "2: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "3: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "4: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "5: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "6: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "7: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤  <Z>\n",
            "\n",
            "M0 = \n",
            "[ 0.1691  0.3316  0.1907 -0.0786 -0.4375  0.3461  0.0699  0.0761]\n",
            "M1 = \n",
            "[[3.453  2.4971 2.5214 5.7016 0.013  2.4136 0.0124 3.0411]\n",
            " [3.7877 2.4384 3.2014 0.4228 1.5739 5.9255 4.4249 2.423 ]\n",
            " [2.0272 0.7587 1.0911 4.8632 6.0885 3.3768 2.0957 2.4795]]\n",
            "0: ─╭AngleEmbedding(M0)─╭BasicEntanglerLayers(M1)─┤  <Z>\n",
            "1: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "2: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "3: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "4: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "5: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "6: ─├AngleEmbedding(M0)─├BasicEntanglerLayers(M1)─┤  <Z>\n",
            "7: ─╰AngleEmbedding(M0)─╰BasicEntanglerLayers(M1)─┤  <Z>\n",
            "\n",
            "M0 = \n",
            "[-0.0706  0.1354  0.149   0.3922  0.3268 -0.2659 -0.4065  0.1324]\n",
            "M1 = \n",
            "[[6.0033 0.7637 1.3603 1.8632 0.1363 0.2251 4.0244 3.5953]\n",
            " [3.2028 0.8011 2.7205 4.6402 0.6621 5.7302 1.4814 4.3423]\n",
            " [3.7551 2.0439 2.899  1.4801 6.2556 3.6263 6.1457 3.5347]]\n"
          ]
        }
      ],
      "source": [
        "print(qml.draw(qnode)([0.1691,  0.3316,  0.1907, -0.0786, -0.4375,  0.3461,  0.0699,  0.0761],[[3.4530, 2.4971, 2.5214, 5.7016, 0.0130, 2.4136, 0.0124, 3.0411],\n",
        "        [3.7877, 2.4384, 3.2014, 0.4228, 1.5739, 5.9255, 4.4249, 2.4230],\n",
        "        [2.0272, 0.7587, 1.0911, 4.8632, 6.0885, 3.3768, 2.0957, 2.4795]]))\n",
        "print(qml.draw(qnode)([-0.0706,  0.1354,  0.1490,  0.3922,  0.3268, -0.2659, -0.4065,  0.1324],[[6.0033, 0.7637, 1.3603, 1.8632, 0.1363, 0.2251, 4.0244, 3.5953],\n",
        "        [3.2028, 0.8011, 2.7205, 4.6402, 0.6621, 5.7302, 1.4814, 4.3423],\n",
        "        [3.7551, 2.0439, 2.8990, 1.4801, 6.2556, 3.6263, 6.1457, 3.5347]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = 3\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "    \n",
        "    \n",
        "    def __init__(self , embeddingSize):\n",
        "        super().__init__()\n",
        "        self.memory = {}\n",
        "        self.inpFormat = torch.nn.Linear(n_qubits*2, n_qubits*2)\n",
        "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.clayer = torch.nn.Linear(2*n_qubits, embeddingSize)\n",
        "\n",
        "\n",
        "\n",
        "    def __EmbeddingBag__(self,X):\n",
        "        \n",
        "        if str(X) in self.memory:\n",
        "            # Check if index is Cached\n",
        "            return self.memory[str(X)]\n",
        "        #Formatting Index into Binary\n",
        "        x = torch.tensor(bitwise_input(int(X) , n_qubits*2))\n",
        "        #Convert Binary output into float\n",
        "        x = self.inpFormat(x.float())\n",
        "        #Split Layer into 2 seperate Quantum Circuits\n",
        "        x_1 = self.qlayer_1(x[:n_qubits-1])\n",
        "        x_2 = self.qlayer_2(x[n_qubits:])\n",
        "        \n",
        "        #Concatnate and Resize output\n",
        "        x = torch.cat([x_1, x_2], axis=-1)\n",
        "        x = self.clayer(x.float())\n",
        "        \n",
        "        #Cache Value\n",
        "        self.memory[str(X)] = x\n",
        "        return x\n",
        "    \n",
        "    def __RecursiveBag__(self,x):\n",
        "        #print(x.dim())\n",
        "        if x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "        \n",
        "        Bag = []\n",
        "        for subtensor in x:\n",
        "            Bag.append(self.__RecursiveBag__(subtensor))\n",
        "        #print(Bag)\n",
        "        return torch.stack(Bag)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if  x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "        return self.__RecursiveBag__(x)\n",
        "\n",
        "qmodel = HybridModel(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HybridModel(\n",
            "  (inpFormat): Linear(in_features=16, out_features=16, bias=True)\n",
            "  (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
            "  (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
            "  (clayer): Linear(in_features=16, out_features=64, bias=True)\n",
            ")\n",
            "tensor([-0.0706,  0.1354,  0.1490,  0.3922,  0.3268, -0.2659, -0.4065,  0.1324,\n",
            "         0.1691,  0.3316,  0.1907, -0.0786, -0.4375,  0.3461,  0.0699,  0.0761],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0138, -0.0513, -0.1983, -0.0785,  0.1334, -0.0053, -0.1481, -0.1005,\n",
            "         -0.2271, -0.1507,  0.1297, -0.0027, -0.2455,  0.2287,  0.1284,  0.1905,\n",
            "          0.1963, -0.2071, -0.0652, -0.0347,  0.2451, -0.0676,  0.1241, -0.2435,\n",
            "         -0.0855, -0.1149,  0.0262,  0.0659,  0.1848, -0.1843, -0.1730,  0.1916,\n",
            "          0.0383, -0.2340, -0.1323, -0.0296, -0.1259,  0.0620,  0.1016, -0.1007,\n",
            "         -0.0172, -0.1773, -0.1013, -0.2012,  0.2671, -0.1175,  0.0943, -0.0631,\n",
            "         -0.0810,  0.1571,  0.0251, -0.0820,  0.0094, -0.0637,  0.0139, -0.2580,\n",
            "         -0.0346,  0.2324,  0.0957, -0.2013, -0.1148, -0.2067,  0.0971,  0.1013]],\n",
            "       grad_fn=<StackBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(qmodel)\n",
        "print(qmodel(torch.tensor([13])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "# Testing Hybrid Model for Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "from random import randint\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0384,  0.1800,  0.0995, -0.8978], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.0340, -0.0398,  0.3288, -0.7351], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.0340, -0.0398,  0.3288, -0.7351], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.1575, -0.2312,  0.0074, -0.5606], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.2351, -0.2844,  0.0578, -1.1306], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1115, -0.4758, -0.2636, -0.9561], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1115, -0.4758, -0.2636, -0.9561], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.3075,  0.4245,  0.3704, -0.5023], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.4311,  0.2331,  0.0490, -0.3278], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.4311,  0.2331,  0.0490, -0.3278], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.4311,  0.2331,  0.0490, -0.3278], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "testrange = 32\n",
        "out = []\n",
        "inp = -1\n",
        "for i in range(testrange):\n",
        "    inp +=1\n",
        "    #print(inp)\n",
        "    X = torch.tensor([inp])\n",
        "    out.append(qmodel(X).detach().numpy().reshape([64]).tolist())\n",
        "\n",
        "sb.heatmap(out,cmap= sb.color_palette(\"coolwarm\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('inpFormat.weight', Parameter containing:\n",
            "tensor([[-0.0796,  0.1649,  0.2464,  0.1117, -0.1030,  0.2238, -0.0297, -0.2086,\n",
            "          0.0708,  0.1248,  0.1470,  0.0860, -0.0316, -0.0054, -0.2467,  0.1562],\n",
            "        [ 0.1871,  0.1745,  0.1956,  0.2062,  0.2134,  0.1249, -0.0525,  0.0204,\n",
            "          0.1768,  0.1404,  0.0305, -0.1402, -0.1032,  0.0530, -0.2210, -0.0010],\n",
            "        [-0.1243, -0.1003, -0.2470,  0.2087,  0.0193,  0.0235, -0.0659,  0.1621,\n",
            "          0.1156,  0.2183,  0.1683,  0.1556,  0.0773,  0.1220, -0.2098,  0.0469],\n",
            "        [-0.0589, -0.0453, -0.1771,  0.1576, -0.2455,  0.1653,  0.0861,  0.2254,\n",
            "         -0.0566,  0.1496,  0.0623,  0.1109,  0.1309, -0.1684,  0.0008,  0.2255],\n",
            "        [-0.0984, -0.2346,  0.1093,  0.1557, -0.0201,  0.1956, -0.2016, -0.1573,\n",
            "         -0.0633, -0.1203,  0.2187,  0.0542,  0.0052,  0.1139,  0.1121,  0.1542],\n",
            "        [-0.1899, -0.0812,  0.2463,  0.0955, -0.1028, -0.1507, -0.2079, -0.1810,\n",
            "         -0.0728,  0.1807,  0.0780, -0.2342,  0.0323,  0.0987, -0.0478, -0.2486],\n",
            "        [-0.1811,  0.0737, -0.1216, -0.0873,  0.2437,  0.0227,  0.1091,  0.2036,\n",
            "          0.2115,  0.2171,  0.0816,  0.2151, -0.0978, -0.1637, -0.1907, -0.1647],\n",
            "        [-0.0988,  0.0392, -0.1189,  0.1813,  0.2173, -0.0339,  0.1436,  0.1853,\n",
            "          0.0624, -0.1589,  0.1462, -0.1267,  0.0007, -0.1297, -0.2274,  0.1618],\n",
            "        [-0.1357,  0.1297, -0.2312, -0.1269,  0.0527, -0.1726,  0.0487, -0.0360,\n",
            "         -0.2300,  0.1516,  0.1758, -0.0073,  0.2458, -0.2075, -0.2120, -0.0856],\n",
            "        [-0.1273,  0.1961, -0.1439,  0.1720,  0.0140, -0.0985,  0.0713, -0.0882,\n",
            "         -0.2092,  0.2028,  0.1155,  0.1623,  0.2059,  0.0576, -0.1775,  0.1956],\n",
            "        [-0.1112, -0.0255, -0.1439,  0.0513, -0.1812,  0.1088,  0.0095,  0.1103,\n",
            "         -0.0553,  0.1732, -0.0962, -0.0691,  0.0702,  0.1307, -0.2366,  0.0344],\n",
            "        [-0.1002, -0.0342,  0.2267,  0.0730,  0.1358,  0.1958,  0.1103,  0.1588,\n",
            "          0.0303, -0.2314, -0.2202, -0.2374,  0.1278, -0.0938,  0.2240, -0.1716],\n",
            "        [-0.2473,  0.1957, -0.0375, -0.2289,  0.0883, -0.0362, -0.2054, -0.1964,\n",
            "         -0.2463, -0.1358,  0.2176, -0.1114, -0.2304, -0.2323, -0.2147, -0.2039],\n",
            "        [-0.0667, -0.0957, -0.1826,  0.0172,  0.1844, -0.0654, -0.2329, -0.0288,\n",
            "          0.0549,  0.2229, -0.1868,  0.0662,  0.1022, -0.1341,  0.1487,  0.2285],\n",
            "        [-0.0445, -0.1902, -0.1566, -0.0123, -0.1710, -0.2381,  0.2411, -0.0941,\n",
            "         -0.1222, -0.1805, -0.1276, -0.0716, -0.0838, -0.0882,  0.0145,  0.0333],\n",
            "        [ 0.0113,  0.1478, -0.1175,  0.0423,  0.0317, -0.2118,  0.0652,  0.0728,\n",
            "          0.1546,  0.1998,  0.2100, -0.2435,  0.1262, -0.1901, -0.1562, -0.1043]],\n",
            "       requires_grad=True))\n",
            "('inpFormat.bias', Parameter containing:\n",
            "tensor([-0.1899,  0.1866, -0.0972,  0.2041,  0.0534, -0.1482,  0.0197,  0.0997,\n",
            "         0.2165, -0.1275, -0.0446,  0.0590,  0.2291,  0.1495,  0.2087,  0.2443],\n",
            "       requires_grad=True))\n",
            "('qlayer_1.weights', Parameter containing:\n",
            "tensor([[3.4530, 2.4971, 2.5214, 5.7016, 0.0130, 2.4136, 0.0124, 3.0411],\n",
            "        [3.7877, 2.4384, 3.2014, 0.4228, 1.5739, 5.9255, 4.4249, 2.4230],\n",
            "        [2.0272, 0.7587, 1.0911, 4.8632, 6.0885, 3.3768, 2.0957, 2.4795]],\n",
            "       requires_grad=True))\n",
            "('qlayer_2.weights', Parameter containing:\n",
            "tensor([[6.0033, 0.7637, 1.3603, 1.8632, 0.1363, 0.2251, 4.0244, 3.5953],\n",
            "        [3.2028, 0.8011, 2.7205, 4.6402, 0.6621, 5.7302, 1.4814, 4.3423],\n",
            "        [3.7551, 2.0439, 2.8990, 1.4801, 6.2556, 3.6263, 6.1457, 3.5347]],\n",
            "       requires_grad=True))\n",
            "('clayer.weight', Parameter containing:\n",
            "tensor([[-0.1105,  0.0013,  0.0818,  ..., -0.1766,  0.1483,  0.0401],\n",
            "        [ 0.1866,  0.0668,  0.1397,  ...,  0.1199, -0.1574, -0.1502],\n",
            "        [-0.1827,  0.1134,  0.0560,  ...,  0.1960,  0.1752,  0.1167],\n",
            "        ...,\n",
            "        [ 0.0016,  0.0721,  0.0468,  ...,  0.2066, -0.1702, -0.1084],\n",
            "        [ 0.0183, -0.0464, -0.1600,  ...,  0.1002, -0.2064,  0.2428],\n",
            "        [-0.1359,  0.2410,  0.2313,  ..., -0.2148, -0.0832,  0.0153]],\n",
            "       requires_grad=True))\n",
            "('clayer.bias', Parameter containing:\n",
            "tensor([-0.0035, -0.0366, -0.1881, -0.0783,  0.1425, -0.0088, -0.1251, -0.0966,\n",
            "        -0.2118, -0.1274,  0.1556, -0.0029, -0.2470,  0.2364,  0.1284,  0.2112,\n",
            "         0.1922, -0.2127, -0.0532, -0.0591,  0.2409, -0.0605,  0.1244, -0.2306,\n",
            "        -0.1054, -0.1248,  0.0404,  0.0805,  0.1850, -0.1823, -0.1793,  0.1876,\n",
            "         0.0657, -0.2183, -0.1221, -0.0394, -0.1169,  0.0509,  0.0884, -0.0776,\n",
            "        -0.0098, -0.2122, -0.1150, -0.1974,  0.2318, -0.0993,  0.0840, -0.0703,\n",
            "        -0.0802,  0.1516,  0.0051, -0.0697,  0.0218, -0.0854,  0.0328, -0.2481,\n",
            "        -0.0256,  0.2426,  0.1015, -0.1964, -0.1156, -0.1564,  0.1047,  0.0806],\n",
            "       requires_grad=True))\n"
          ]
        }
      ],
      "source": [
        "for i in qmodel.named_parameters():\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Declaring Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "c8bc3725-3f1c-440d-84c9-0a194fd89e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding_layer): HybridModel(\n",
            "    (inpFormat): Linear(in_features=16, out_features=16, bias=True)\n",
            "    (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
            "    (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
            "    (clayer): Linear(in_features=16, out_features=64, bias=True)\n",
            "  )\n",
            "  (rnn): RNN(64, 32, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = HybridModel(64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "model = RNN()\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Linear(in_features=16, out_features=16, bias=True)                                    2                 2                    272                                     \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    24                                      \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    24                                      \n",
            "Linear(in_features=16, out_features=64, bias=True)                                    2                 2                    1,088                                   \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 9,890\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9890"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from word2ket import EmbeddingKet, EmbeddingKetXS , ketify,summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.017, momentum=0.9)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "ea4031a7-e6ef-4e62-f9df-1f82601c52f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/30 [00:00<?, ?batch/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/30 [00:00<?, ?batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 0.1615,  0.4377,  0.5535, -0.0857], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5451,  0.5548,  0.5220,  0.1098], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4102,  0.3830,  1.1947, -0.3095], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.6143,  0.0468,  0.4126, -0.2808], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.2939,  0.3281,  0.1467,  0.0264], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5288, -0.0409,  0.9716, -0.6557], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.2084,  0.2404,  0.7058, -0.3484], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4102,  0.3830,  1.1947, -0.3095], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1589,  0.1563,  0.8194, -0.3929], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4102,  0.3830,  1.1947, -0.3095], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.6638,  0.1308,  0.2989, -0.2364], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5451,  0.5548,  0.5220,  0.1098], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4102,  0.3830,  1.1947, -0.3095], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0403,  0.5803,  1.0425, -0.0467], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0403,  0.5803,  1.0425, -0.0467], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5451,  0.5548,  0.5220,  0.1098], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5451,  0.5548,  0.5220,  0.1098], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.5451,  0.5548,  0.5220,  0.1098], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.8656,  0.2735,  0.7879, -0.1974], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0403,  0.5803,  1.0425, -0.0467], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.1753,  0.7521,  0.3698,  0.3726], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.9842, -0.1505,  0.5648, -0.5436], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0403,  0.5803,  1.0425, -0.0467], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0403,  0.5803,  1.0425, -0.0467], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n",
            "tensor([0.2801, 0.8616, 0.7766, 0.2605], grad_fn=<ViewBackward0>)\n",
            "tensor([-0.0897,  0.6644,  0.9289, -0.0023], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/30 [00:08<?, ?batch/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.4957,  0.4707,  0.6357,  0.0654], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[59], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# Training pass\u001b[39;00m\n\u001b[0;32m      8\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m output \u001b[39m=\u001b[39m model(text)\n\u001b[0;32m     12\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, tgt)\n\u001b[0;32m     14\u001b[0m \u001b[39m#This is where the model learns by backpropagating\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[55], line 12\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, X_batch)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X_batch):\n\u001b[1;32m---> 12\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_layer(X_batch)\n\u001b[0;32m     13\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(embeddings)\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(output[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])))))\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[41], line 42\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m  x\u001b[39m.\u001b[39mdim()\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__EmbeddingBag__(x)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(x)\n",
            "Cell \u001b[1;32mIn[41], line 36\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n\u001b[1;32m---> 36\u001b[0m     Bag\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(subtensor))\n\u001b[0;32m     37\u001b[0m \u001b[39m#print(Bag)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(Bag)\n",
            "Cell \u001b[1;32mIn[41], line 36\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n\u001b[1;32m---> 36\u001b[0m     Bag\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(subtensor))\n\u001b[0;32m     37\u001b[0m \u001b[39m#print(Bag)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(Bag)\n",
            "Cell \u001b[1;32mIn[41], line 32\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__RecursiveBag__\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m     31\u001b[0m     \u001b[39m#print(x.dim())\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdim()\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__EmbeddingBag__(x)\n\u001b[0;32m     34\u001b[0m     Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n",
            "Cell \u001b[1;32mIn[41], line 22\u001b[0m, in \u001b[0;36mHybridModel.__EmbeddingBag__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     20\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minpFormat(x\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(x)\n\u001b[1;32m---> 22\u001b[0m x_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqlayer_1(x)\n\u001b[0;32m     23\u001b[0m x_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqlayer_2(x)\n\u001b[0;32m     24\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x_1, x_2], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnn\\torch.py:402\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    399\u001b[0m     inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(inputs, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, inputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m    401\u001b[0m \u001b[39m# calculate the forward pass as usual\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_qnode(inputs)\n\u001b[0;32m    404\u001b[0m \u001b[39m# reshape to the correct number of batch dims\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m has_batch_dim:\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnn\\torch.py:423\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \n\u001b[0;32m    413\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    420\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_arg: x},\n\u001b[0;32m    421\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{arg: weight\u001b[39m.\u001b[39mto(x) \u001b[39mfor\u001b[39;00m arg, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnode_weights\u001b[39m.\u001b[39mitems()},\n\u001b[0;32m    422\u001b[0m }\n\u001b[1;32m--> 423\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnode.py:1039\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1034\u001b[0m         full_transform_program\u001b[39m.\u001b[39m_set_all_argnums(\n\u001b[0;32m   1035\u001b[0m             \u001b[39mself\u001b[39m, args, kwargs, argnums\n\u001b[0;32m   1036\u001b[0m         )  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1040\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,),\n\u001b[0;32m   1041\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[0;32m   1042\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[0;32m   1043\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[0;32m   1044\u001b[0m     transform_program\u001b[39m=\u001b[39;49mfull_transform_program,\n\u001b[0;32m   1045\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m   1046\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[0;32m   1047\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[0;32m   1048\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[0;32m   1049\u001b[0m )\n\u001b[0;32m   1051\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1053\u001b[0m \u001b[39m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:648\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m no_interface_boundary_required:\n\u001b[1;32m--> 648\u001b[0m     results \u001b[39m=\u001b[39m inner_execute(tapes)\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m post_processing(results)\n\u001b[0;32m    651\u001b[0m _grad_on_execution \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:261\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m numpy_only:\n\u001b[0;32m    260\u001b[0m     tapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(qml\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tapes)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mreturn\u001b[39;00m cached_device_execution(tapes)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:383\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[0;32m    380\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[39m# convert to list as new device interface returns a tuple\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(fn(\u001b[39mtuple\u001b[39;49m(execution_tapes\u001b[39m.\u001b[39;49mvalues()), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    385\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[0;32m    387\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:523\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m    517\u001b[0m interface \u001b[39m=\u001b[39m (\n\u001b[0;32m    518\u001b[0m     execution_config\u001b[39m.\u001b[39minterface\n\u001b[0;32m    519\u001b[0m     \u001b[39mif\u001b[39;00m execution_config\u001b[39m.\u001b[39mgradient_method \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    520\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m max_workers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    524\u001b[0m         simulate(\n\u001b[0;32m    525\u001b[0m             c,\n\u001b[0;32m    526\u001b[0m             rng\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rng,\n\u001b[0;32m    527\u001b[0m             prng_key\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prng_key,\n\u001b[0;32m    528\u001b[0m             debugger\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debugger,\n\u001b[0;32m    529\u001b[0m             interface\u001b[39m=\u001b[39minterface,\n\u001b[0;32m    530\u001b[0m             state_cache\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_cache,\n\u001b[0;32m    531\u001b[0m         )\n\u001b[0;32m    532\u001b[0m         \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     vanilla_circuits \u001b[39m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits]\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:524\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    517\u001b[0m interface \u001b[39m=\u001b[39m (\n\u001b[0;32m    518\u001b[0m     execution_config\u001b[39m.\u001b[39minterface\n\u001b[0;32m    519\u001b[0m     \u001b[39mif\u001b[39;00m execution_config\u001b[39m.\u001b[39mgradient_method \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    520\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m max_workers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m--> 524\u001b[0m         simulate(\n\u001b[0;32m    525\u001b[0m             c,\n\u001b[0;32m    526\u001b[0m             rng\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    527\u001b[0m             prng_key\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prng_key,\n\u001b[0;32m    528\u001b[0m             debugger\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_debugger,\n\u001b[0;32m    529\u001b[0m             interface\u001b[39m=\u001b[39;49minterface,\n\u001b[0;32m    530\u001b[0m             state_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state_cache,\n\u001b[0;32m    531\u001b[0m         )\n\u001b[0;32m    532\u001b[0m         \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     vanilla_circuits \u001b[39m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits]\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:243\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(circuit, rng, prng_key, debugger, interface, state_cache)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m state_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     state_cache[circuit\u001b[39m.\u001b[39mhash] \u001b[39m=\u001b[39m state\n\u001b[1;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m measure_final_state(circuit, state, is_state_batched, rng\u001b[39m=\u001b[39;49mrng, prng_key\u001b[39m=\u001b[39;49mprng_key)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:177\u001b[0m, in \u001b[0;36mmeasure_final_state\u001b[1;34m(circuit, state, is_state_batched, rng, prng_key)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(circuit\u001b[39m.\u001b[39mmeasurements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    175\u001b[0m         \u001b[39mreturn\u001b[39;00m measure(circuit\u001b[39m.\u001b[39mmeasurements[\u001b[39m0\u001b[39m], state, is_state_batched\u001b[39m=\u001b[39mis_state_batched)\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    178\u001b[0m         measure(mp, state, is_state_batched\u001b[39m=\u001b[39mis_state_batched) \u001b[39mfor\u001b[39;00m mp \u001b[39min\u001b[39;00m circuit\u001b[39m.\u001b[39mmeasurements\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[39m# finite-shot case\u001b[39;00m\n\u001b[0;32m    183\u001b[0m rng \u001b[39m=\u001b[39m default_rng(rng)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:178\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(circuit\u001b[39m.\u001b[39mmeasurements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    175\u001b[0m         \u001b[39mreturn\u001b[39;00m measure(circuit\u001b[39m.\u001b[39mmeasurements[\u001b[39m0\u001b[39m], state, is_state_batched\u001b[39m=\u001b[39mis_state_batched)\n\u001b[0;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m--> 178\u001b[0m         measure(mp, state, is_state_batched\u001b[39m=\u001b[39;49mis_state_batched) \u001b[39mfor\u001b[39;00m mp \u001b[39min\u001b[39;00m circuit\u001b[39m.\u001b[39mmeasurements\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[39m# finite-shot case\u001b[39;00m\n\u001b[0;32m    183\u001b[0m rng \u001b[39m=\u001b[39m default_rng(rng)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\measure.py:234\u001b[0m, in \u001b[0;36mmeasure\u001b[1;34m(measurementprocess, state, is_state_batched)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure\u001b[39m(\n\u001b[0;32m    222\u001b[0m     measurementprocess: MeasurementProcess, state: TensorLike, is_state_batched: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    223\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TensorLike:\n\u001b[0;32m    224\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply a measurement process to a state.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m        Tensorlike: the result of the measurement\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m get_measurement_function(measurementprocess, state)(\n\u001b[0;32m    235\u001b[0m         measurementprocess, state, is_state_batched\n\u001b[0;32m    236\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\measure.py:71\u001b[0m, in \u001b[0;36mstate_diagonalizing_gates\u001b[1;34m(measurementprocess, state, is_state_batched)\u001b[0m\n\u001b[0;32m     69\u001b[0m total_indices \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(state\u001b[39m.\u001b[39mshape) \u001b[39m-\u001b[39m is_state_batched\n\u001b[0;32m     70\u001b[0m wires \u001b[39m=\u001b[39m Wires(\u001b[39mrange\u001b[39m(total_indices))\n\u001b[1;32m---> 71\u001b[0m flattened_state \u001b[39m=\u001b[39m flatten_state(state, total_indices)\n\u001b[0;32m     72\u001b[0m \u001b[39mreturn\u001b[39;00m measurementprocess\u001b[39m.\u001b[39mprocess_state(flattened_state, wires)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\measure.py:50\u001b[0m, in \u001b[0;36mflatten_state\u001b[1;34m(state, num_wires)\u001b[0m\n\u001b[0;32m     48\u001b[0m batch_size \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mget_batch_size(state, (\u001b[39m2\u001b[39m,) \u001b[39m*\u001b[39m num_wires, dim)\n\u001b[0;32m     49\u001b[0m shape \u001b[39m=\u001b[39m (batch_size, dim) \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (dim,)\n\u001b[1;32m---> 50\u001b[0m \u001b[39mreturn\u001b[39;00m math\u001b[39m.\u001b[39;49mreshape(state, shape)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autoray\\autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m backend \u001b[39m=\u001b[39m choose_backend(fn, \u001b[39m*\u001b[39margs, like\u001b[39m=\u001b[39mlike, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 80\u001b[0m \u001b[39mreturn\u001b[39;00m get_lib_fn(backend, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader , unit = \"batch\") as tepoch:\n",
        "      for text, tgt in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {e}\")\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward(retain_graph=True)\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        tepoch.set_postfix(loss=loss.item())\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "        \n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "      \n",
        "        \n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "  #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
