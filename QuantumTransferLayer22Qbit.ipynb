{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "7cad9b15-3b3a-4f68-cf88-cc540cf3bf76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pennylane in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.34.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (1.24.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (1.12.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (3.1)\n",
            "Requirement already satisfied: rustworkx in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (0.14.0)\n",
            "Requirement already satisfied: autograd in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version>=2.7 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (2.10.0)\n",
            "Requirement already satisfied: autoray>=0.6.1 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (0.6.7)\n",
            "Requirement already satisfied: cachetools in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (5.3.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.34 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (0.34.0)\n",
            "Requirement already satisfied: requests in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pennylane) (4.9.0)\n",
            "Requirement already satisfied: future>=0.15.2 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pennylane) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pennylane) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->pennylane) (2023.11.17)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "dcca8136-f9fb-47fc-9175-abc9c3023247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data, test = train_test_split(data, test_size=0.95)\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "b140241d-410d-4fc3-8745-40b02f372e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()), batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()),batch_size=4)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "2000eb65-678e-42cc-dc0b-e552c00773e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "3992        3992  meals without washing their hands. There the o...     True\n",
            "1559        1559  lie and. To inhale flesh and the lofty Shrapne...     True\n",
            "4355        4355  outinto the dark river Swift and cold weather ...     True\n",
            "4654        4654  Nothing to do but scuff down the graveyard roa...    False\n",
            "3807        3807  My parents kept me from children who were roug...    False\n",
            "...          ...                                                ...      ...\n",
            "2182        2182  shrilling pocked and frozen ground. And low Th...     True\n",
            "1344        1344  meet me. Joy Did the bother with this year of ...     True\n",
            "2584        2584  With measured pace, they move in single file, ...    False\n",
            "3313        3313  Down here, no light but what we carry with us....    False\n",
            "3089        3089  went head of the rocks occasionally. Everythin...     True\n",
            "\n",
            "[192 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "1927        1927  Over my head, I see the bronze butterfly,    A...    False\n",
            "2340        2340  Imaginary book on Imaginary paper in Imaginary...    False\n",
            "1967        1967  Take hold of the bitter end; \\npass carefully ...    False\n",
            "2471        2471  Life kept rolling her over    like a piece of ...    False\n",
            "1587        1587  Days you are sick, we get dressed slow, find o...    False\n",
            "...          ...                                                ...      ...\n",
            "4248        4248  All trembling in my arms Aminta lay, Defending...    False\n",
            "1378        1378  A woman’s face with nature’s own hand painted ...    False\n",
            "4282        4282  wedged in the false summit. How much longer ti...     True\n",
            "4499        4499  elevatorI crouched like you had been too many ...     True\n",
            "52            52  Her body is not so white as anemony petals nor...    False\n",
            "\n",
            "[766 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6hk9hSBN-B"
      },
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLWwIBW9BN-C",
        "outputId": "1ca0ed8a-3ade-492a-cd79-a497faefc2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n"
          ]
        }
      ],
      "source": [
        "def bitwise_input(input,n_max = 16):\n",
        "    bits = []\n",
        "    for i in bin(input)[2:]:\n",
        "        bits.append(int(i))\n",
        "    # filling\n",
        "    for _ in range(n_max - len(bits)):\n",
        "        bits.insert(0,0)\n",
        "    return bits[:n_max]\n",
        "\n",
        "print(bitwise_input(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n_X6JppDBN-D"
      },
      "outputs": [],
      "source": [
        "def getProb(prob,nmax = 16):\n",
        "    out = []\n",
        "    for i in range(nmax):\n",
        "        out.append(prob[2**nmax-1])\n",
        "    print(out)\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VokNOBorBN-E"
      },
      "source": [
        "# Quantum Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GaTqOEfmBN-E"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "n_qubits = 8\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    #inp = bitwise_input(inputs,n_qubits)\n",
        "    #print(inputs)\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires = i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sRbsk2voBN-F"
      },
      "outputs": [],
      "source": [
        "n_layers = 1\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v6g2ZLx8BN-G"
      },
      "outputs": [],
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self , embeddingSize):\n",
        "        super().__init__()\n",
        "        self.memory = {}\n",
        "        self.inpFormat = torch.nn.Linear(16, n_qubits*2)\n",
        "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.clayer = torch.nn.Linear(2*n_qubits, embeddingSize)\n",
        "\n",
        "\n",
        "\n",
        "    def __EmbeddingBag__(self,X):\n",
        "\n",
        "        if str(X) in self.memory:\n",
        "            # Check if index is Cached\n",
        "            return self.memory[str(X)].clone()\n",
        "        #Formatting Index into Binary\n",
        "        x = torch.tensor(bitwise_input(int(X) , 16))\n",
        "        #Convert Binary output into float\n",
        "        x = self.inpFormat(x.float())\n",
        "        #Split Layer into 2 seperate Quantum Circuits\n",
        "        x_1 = self.qlayer_1(x[:n_qubits-1])\n",
        "        x_2 = self.qlayer_2(x[n_qubits :])\n",
        "\n",
        "\n",
        "        #Concatnate and Resize output\n",
        "        xc = torch.cat([x_1 , x_2], axis=-1)\n",
        "        xc = self.clayer(xc.float())\n",
        "        xcn = torch.nn.functional.normalize(xc,dim = 0)\n",
        "        #Cache Value\n",
        "        self.memory[str(X)] = xc.clone()\n",
        "        return xc\n",
        "\n",
        "    def __RecursiveBag__(self,x):\n",
        "        #print(x.dim())\n",
        "        if x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "\n",
        "        Bag = []\n",
        "        for subtensor in x:\n",
        "            Bag.append(self.__RecursiveBag__(subtensor))\n",
        "        #print(Bag)\n",
        "        return torch.stack(Bag)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.memory = {}\n",
        "        if  x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "        return self.__RecursiveBag__(x)\n",
        "\n",
        "#qmodel = HybridModel(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "96He1EE-BN-H"
      },
      "outputs": [],
      "source": [
        "#print(qmodel)\n",
        "#print(qmodel(torch.tensor([13])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "# Testing Hybrid Model for Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XeLyUWUrBN-I"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZdapHwbBN-J"
      },
      "source": [
        "# Declaring Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lho9HQKX5xQ4"
      },
      "outputs": [],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = HybridModel(64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "#model = RNN()\n",
        "\n",
        "#print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "d_s33-_-kVSr"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "dbfile = open('ClassicOriginalModel', 'rb')\n",
        "model = pickle.load(dbfile)\n",
        "dbfile.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwL98-FwEWsu",
        "outputId": "1a03a91a-7155-4a4d-ad10-6df5e6eecc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: word2ket in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.2)\n",
            "Requirement already satisfied: torch in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from word2ket) (2.2.0)\n",
            "Requirement already satisfied: gpytorch in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from word2ket) (1.11)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gpytorch->word2ket) (1.4.0)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gpytorch->word2ket) (0.5.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->word2ket) (2023.12.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (1.12.0)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (0.2.25)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (2.13.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->word2ket) (2.1.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->gpytorch->word2ket) (1.24.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->gpytorch->word2ket) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->gpytorch->word2ket) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\shado\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->word2ket) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install word2ket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSekXgzPBN-K",
        "outputId": "312c5d1a-014f-47eb-b7ec-3188a08deca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Embedding(18658, 64)                                                                  1                 1                    1,194,112                               \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 1,202,594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1202594"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from word2ket import summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_NaRn2fkofp",
        "outputId": "0b820961-ff52-4675-eba7-6ef0691fee40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Embedding(18658, 64)                                                                  1                 0                    0                                       \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                0                    0                                       \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 0                    0                                       \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 0                    0                                       \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for layer in model.parameters():\n",
        "  layer.requires_grad = False\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kCUsEJam3Xc",
        "outputId": "a4b50bcb-4774-42de-bd7e-4fb6529d3902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Linear(in_features=16, out_features=4, bias=True)                                     2                 2                    68                                      \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    4                                       \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    4                                       \n",
            "Linear(in_features=4, out_features=64, bias=True)                                     2                 2                    320                                     \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                0                    0                                       \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 0                    0                                       \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 0                    0                                       \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 396\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "396"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.embedding_layer = HybridModel(64)\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ClGhRFaJBN-M"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "e1df98c7-56dd-46e6-9965-1c74c64d0c8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/192 [00:00<?, ?batch/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 192/192 [24:48:47<00:00, 465.25s/batch, loss=0.665]    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 - Training loss: 0.7351990966126323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/48 [34:26<?, ?items/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy = 0.640625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy = []\n",
        "epochs = 1\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader , unit = \"batch\") as tepoch:\n",
        "      for text, tgt in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {e}\")\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "          optimizer.zero_grad()\n",
        "          output = model(text)\n",
        "          loss = criterion(output, tgt)\n",
        "          loss.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "        tepoch.set_postfix(loss=loss.item())\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      else:\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(train_loader)))\n",
        "\n",
        "\n",
        "    correct_count, all_count = 0, 0\n",
        "    with tqdm.tqdm(test_loader , unit = \"items\") as tepoch:\n",
        "      for images,labels in test_loader:\n",
        "        for i in range(len(labels)):\n",
        "          img = images[i].view(1,-1)\n",
        "          with torch.no_grad():\n",
        "            logps = model(img)\n",
        "\n",
        "          ps = torch.exp(logps)\n",
        "          probab = list(ps.numpy()[0])\n",
        "          pred_label = probab.index(max(probab))\n",
        "          true_label = labels.numpy()[i]\n",
        "\n",
        "          if(true_label == pred_label):\n",
        "            correct_count += 1\n",
        "          all_count += 1\n",
        "\n",
        "      print(\"Model Accuracy =\", (correct_count/all_count))\n",
        "      accuracy.append((correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FsCDg-tt-dFQ"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "dbfile = open('2QubitParams', 'wb')\n",
        "\n",
        "pickle.dump(model.state_dict(), dbfile)\n",
        "dbfile.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
