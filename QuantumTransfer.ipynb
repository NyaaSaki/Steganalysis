{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "87b3732f-276d-4c48-d879-91eb23236799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.34.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.11.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.2.1)\n",
            "Requirement already satisfied: rustworkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.14.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.6.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: semantic-version>=2.7 in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.10.0)\n",
            "Requirement already satisfied: autoray>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.6.8)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.34 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.34.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.9.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "dabe337e-7b4f-405e-e02c-99642636a0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data, test = train_test_split(data, test_size=0.4)\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "6d223a96-8593-49b0-a2a2-eef371de9c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()), batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()),batch_size=4)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "75d091ab-c937-4b6c-81aa-1d3db0b44664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "4600        4600  Last night in bedI mouthed a prayerof my own c...    False\n",
            "907          907  a thick river. I have ignored in fear of God. ...     True\n",
            "2432        2432  Then one day she noticed the forest had begun ...    False\n",
            "1183        1183  Then the mighty undulations of thy mind. Out o...     True\n",
            "3446        3446  Imagine, not even or really ever tastinga peac...    False\n",
            "...          ...                                                ...      ...\n",
            "435          435  I In September beyond the breezes and the smok...    False\n",
            "2582        2582  the busy race to cheer when he got to the bed ...     True\n",
            "1948        1948  How sweet I roam'd from field to field, ; ;And...    False\n",
            "1881        1881  Crashing again—Basquiat sends fenders & letter...    False\n",
            "3741        3741  As if the moon could haul through you Its trem...    False\n",
            "\n",
            "[576 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "60            60  womb The whole notes of chimney sweep. And lik...     True\n",
            "4279        4279  It is the miller’s daughter,  And she is grown...    False\n",
            "787          787  the big as the faint reflections This is our m...     True\n",
            "3257        3257  The tide rises, the tide falls, The twilight d...    False\n",
            "3574        3574  Brief as a fist. Nor still that makes me do th...     True\n",
            "...          ...                                                ...      ...\n",
            "2659        2659  it One fit its tentacles. Hide When the god wa...     True\n",
            "3047        3047  You are blind like us. Your hurt no man design...    False\n",
            "1355        1355  When forty winters shall besiege thy brow And ...    False\n",
            "3723        3723  I wondered how long I could go on once the rai...    False\n",
            "2931        2931  radiant in what he asked if a Year old lady st...     True\n",
            "\n",
            "[2300 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6hk9hSBN-B"
      },
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DLWwIBW9BN-C",
        "outputId": "9f97dcbf-f99e-43cb-d475-6e2f14508177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1]\n"
          ]
        }
      ],
      "source": [
        "def bitwise_input(input,n_max = 16):\n",
        "    bits = []\n",
        "    for i in bin(input)[2:]:\n",
        "        bits.append(int(i))\n",
        "    # filling\n",
        "    for _ in range(n_max - len(bits)):\n",
        "        bits.insert(0,0)\n",
        "    return bits[:n_max]\n",
        "\n",
        "print(bitwise_input(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "n_X6JppDBN-D"
      },
      "outputs": [],
      "source": [
        "def getProb(prob,nmax = 16):\n",
        "    out = []\n",
        "    for i in range(nmax):\n",
        "        out.append(prob[2**nmax-1])\n",
        "    print(out)\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VokNOBorBN-E"
      },
      "source": [
        "# Quantum Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GaTqOEfmBN-E"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "n_qubits = 2\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    #inp = bitwise_input(inputs,n_qubits)\n",
        "    #print(inputs)\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires = i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sRbsk2voBN-F"
      },
      "outputs": [],
      "source": [
        "n_layers = 1\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "v6g2ZLx8BN-G"
      },
      "outputs": [],
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self , embeddingSize):\n",
        "        super().__init__()\n",
        "        self.memory = {}\n",
        "        self.inpFormat = torch.nn.Linear(16, n_qubits*2)\n",
        "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.clayer = torch.nn.Linear(2*n_qubits, embeddingSize)\n",
        "\n",
        "\n",
        "\n",
        "    def __EmbeddingBag__(self,X):\n",
        "\n",
        "        if str(X) in self.memory:\n",
        "            # Check if index is Cached\n",
        "            return self.memory[str(X)].clone()\n",
        "        #Formatting Index into Binary\n",
        "        x = torch.tensor(bitwise_input(int(X) , 16))\n",
        "        #Convert Binary output into float\n",
        "        x = self.inpFormat(x.float())\n",
        "        #Split Layer into 2 seperate Quantum Circuits\n",
        "        x_1 = self.qlayer_1(x[:n_qubits-1])\n",
        "        x_2 = self.qlayer_2(x[n_qubits :])\n",
        "\n",
        "\n",
        "        #Concatnate and Resize output\n",
        "        xc = torch.cat([x_1 , x_2], axis=-1)\n",
        "        xc = self.clayer(xc.float())\n",
        "\n",
        "        #Cache Value\n",
        "        self.memory[str(X)] = xc.clone()\n",
        "        return xc\n",
        "\n",
        "    def __RecursiveBag__(self,x):\n",
        "        #print(x.dim())\n",
        "        if x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "\n",
        "        Bag = []\n",
        "        for subtensor in x:\n",
        "            Bag.append(self.__RecursiveBag__(subtensor))\n",
        "        #print(Bag)\n",
        "        return torch.stack(Bag)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.memory = {}\n",
        "        if  x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "        return self.__RecursiveBag__(x)\n",
        "\n",
        "#qmodel = HybridModel(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "96He1EE-BN-H"
      },
      "outputs": [],
      "source": [
        "#print(qmodel)\n",
        "#print(qmodel(torch.tensor([13])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "# Testing Hybrid Model for Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XeLyUWUrBN-I"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "1Tih4sGXBN-I"
      },
      "outputs": [],
      "source": [
        "testrange = 32\n",
        "out = []\n",
        "inp = -1\n",
        "#for i in range(testrange):\n",
        "    #inp +=1\n",
        "    #print(inp)\n",
        "    #X = torch.tensor([inp])\n",
        "    #out.append(qmodel(X).detach().numpy().reshape([64]).tolist())\n",
        "\n",
        "#sb.heatmap(out,cmap= sb.color_palette(\"coolwarm\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xleRvQZyBN-J"
      },
      "outputs": [],
      "source": [
        "#for i in qmodel.named_parameters():\n",
        "    #print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZdapHwbBN-J"
      },
      "source": [
        "# Declaring Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "1b19506f-33c6-4b57-ba82-ea51a7854825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (embedding_layer): HybridModel(\n",
            "    (inpFormat): Linear(in_features=16, out_features=4, bias=True)\n",
            "    (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
            "    (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
            "    (clayer): Linear(in_features=4, out_features=64, bias=True)\n",
            "  )\n",
            "  (rnn): RNN(64, 32, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = HybridModel(64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "model = RNN()\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2ket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwL98-FwEWsu",
        "outputId": "265a4370-c33b-4517-9f03-a1b0eb90a265"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word2ket in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from word2ket) (2.1.0+cu121)\n",
            "Requirement already satisfied: gpytorch in /usr/local/lib/python3.10/dist-packages (from word2ket) (1.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from gpytorch->word2ket) (1.2.2)\n",
            "Requirement already satisfied: linear-operator>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from gpytorch->word2ket) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->word2ket) (2.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (1.11.4)\n",
            "Requirement already satisfied: jaxtyping>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (0.2.25)\n",
            "Requirement already satisfied: typeguard~=2.13.3 in /usr/local/lib/python3.10/dist-packages (from linear-operator>=0.5.0->gpytorch->word2ket) (2.13.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->word2ket) (2.1.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->word2ket) (1.25.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->word2ket) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->gpytorch->word2ket) (3.3.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->word2ket) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kSekXgzPBN-K",
        "outputId": "795b6e7a-fde4-47cd-c877-fcd851679f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Linear(in_features=16, out_features=4, bias=True)                                     2                 2                    68                                      \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    2                                       \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    2                                       \n",
            "Linear(in_features=4, out_features=64, bias=True)                                     2                 2                    320                                     \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 8,874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8874"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "from word2ket import EmbeddingKet, EmbeddingKetXS , ketify,summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.017, momentum=0.9)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ClGhRFaJBN-M"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "848e5eb8-b38d-42fc-f1f3-970fd74058d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   2%|▏         | 9/575 [06:59<7:16:57, 46.32s/batch, loss=0.689]"
          ]
        }
      ],
      "source": [
        "accuracy = []\n",
        "epochs = 1\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader , unit = \"batch\") as tepoch:\n",
        "      for text, tgt in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {e}\")\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "          optimizer.zero_grad()\n",
        "          output = model(text)\n",
        "          loss = criterion(output, tgt)\n",
        "          loss.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "        tepoch.set_postfix(loss=loss.item())\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "\n",
        "\n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "    #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n",
        "    accuracy.append((correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}