{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "87b3732f-276d-4c48-d879-91eb23236799"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [],
      "source": [
        "#!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "dabe337e-7b4f-405e-e02c-99642636a0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data, test = train_test_split(data, test_size=0.9)\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "6d223a96-8593-49b0-a2a2-eef371de9c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "\n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()), batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()),batch_size=4)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "75d091ab-c937-4b6c-81aa-1d3db0b44664"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "4592        4592  weals down. Autumn at dusk and file I come nea...     True\n",
            "4487        4487  s tanning lotion. Dearer far Even than all lov...     True\n",
            "2242        2242  from An Evening's Love    You charm'd me not w...    False\n",
            "2632        2632  Titled after Satie    I. Three pears ripen On ...    False\n",
            "1745        1745  I will arise and go now, and go to Innisfree, ...    False\n",
            "...          ...                                                ...      ...\n",
            "376          376  his darts this soup. Beholding choice molecule...     True\n",
            "3903        3903  One cuts blocks  From the abundant river,  Hau...    False\n",
            "3014        3014  ; ; ; ; ; ; ; ; ; ; ; ; ;~ [our] nightmare : n...    False\n",
            "3898        3898  Gaily bedight,    A gallant knight, In sunshin...    False\n",
            "4571        4571  He never saw a violin. But he saw a lifetime o...    False\n",
            "\n",
            "[96 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "4243        4243  Darling, I leave you the forever unblooming ; ...    False\n",
            "3909        3909  The rat traps emptied, the grain troughs fille...    False\n",
            "450          450  paint over thedead end sign ; ;  are police wr...    False\n",
            "1095        1095  forget. So let my heart. Or they might be tric...     True\n",
            "942          942  The most popular “act” in Penn Station is the ...    False\n",
            "...          ...                                                ...      ...\n",
            "4232        4232  When I hurt you and cast you off, that was buc...    False\n",
            "3218        3218  Your death must be loved this much.   You have...    False\n",
            "2493        2493  Under the roof is the empty room papered in re...    False\n",
            "1583        1583  Near the end of my searching ; ; ; I came to a...    False\n",
            "1827        1827  There is a Smile of Love And there is a Smile ...    False\n",
            "\n",
            "[383 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dy6hk9hSBN-B"
      },
      "source": [
        "## Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLWwIBW9BN-C",
        "outputId": "9f97dcbf-f99e-43cb-d475-6e2f14508177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n"
          ]
        }
      ],
      "source": [
        "def bitwise_input(input,n_max = 16):\n",
        "    bits = []\n",
        "    for i in bin(input)[2:]:\n",
        "        bits.append(int(i))\n",
        "    # filling\n",
        "    for _ in range(n_max - len(bits)):\n",
        "        bits.insert(0,0)\n",
        "    return bits[:n_max]\n",
        "\n",
        "print(bitwise_input(1,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "n_X6JppDBN-D"
      },
      "outputs": [],
      "source": [
        "def getProb(prob,nmax = 16):\n",
        "    out = []\n",
        "    for i in range(nmax):\n",
        "        out.append(prob[2**nmax-1])\n",
        "    print(out)\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VokNOBorBN-E"
      },
      "source": [
        "# Quantum Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GaTqOEfmBN-E"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def qnode(inputs, weights):\n",
        "    #inp = bitwise_input(inputs,n_qubits)\n",
        "    #print(inputs)\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(wires = i)) for i in range(n_qubits)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sRbsk2voBN-F"
      },
      "outputs": [],
      "source": [
        "n_layers = 1\n",
        "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "v6g2ZLx8BN-G"
      },
      "outputs": [],
      "source": [
        "class HybridModel(torch.nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self , embeddingSize):\n",
        "        super().__init__()\n",
        "        self.memory = {}\n",
        "        self.inpFormat = torch.nn.Linear(16, n_qubits*2)\n",
        "        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "        self.clayer = torch.nn.Linear(2*n_qubits, embeddingSize)\n",
        "\n",
        "\n",
        "\n",
        "    def __EmbeddingBag__(self,X):\n",
        "\n",
        "        if str(X) in self.memory:\n",
        "            # Check if index is Cached\n",
        "            return self.memory[str(X)].clone()\n",
        "        #Formatting Index into Binary\n",
        "        x = torch.tensor(bitwise_input(int(X) , 16))\n",
        "        #Convert Binary output into float\n",
        "        x = self.inpFormat(x.float())\n",
        "        #Split Layer into 2 seperate Quantum Circuits\n",
        "        x_1 = self.qlayer_1(x[:n_qubits-1])\n",
        "        x_2 = self.qlayer_2(x[n_qubits :])\n",
        "\n",
        "\n",
        "        #Concatnate and Resize output\n",
        "        xc = torch.cat([x_1 , x_2], axis=-1)\n",
        "        xc = self.clayer(xc.float())\n",
        "\n",
        "        #Cache Value\n",
        "        self.memory[str(X)] = xc.clone()\n",
        "        return xc\n",
        "\n",
        "    def __RecursiveBag__(self,x):\n",
        "        #print(x.dim())\n",
        "        if x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "\n",
        "        Bag = []\n",
        "        for subtensor in x:\n",
        "            Bag.append(self.__RecursiveBag__(subtensor))\n",
        "        #print(Bag)\n",
        "        return torch.stack(Bag)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.memory = {}\n",
        "        if  x.dim()==0: return self.__EmbeddingBag__(x)\n",
        "        return self.__RecursiveBag__(x)\n",
        "\n",
        "qmodel = HybridModel(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "96He1EE-BN-H"
      },
      "outputs": [],
      "source": [
        "print(qmodel)\n",
        "print(qmodel(torch.tensor([13])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "# Testing Hybrid Model for Consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XeLyUWUrBN-I"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "import seaborn as sb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1Tih4sGXBN-I"
      },
      "outputs": [],
      "source": [
        "testrange = 32\n",
        "out = []\n",
        "inp = -1\n",
        "#for i in range(testrange):\n",
        "    #inp +=1\n",
        "    #print(inp)\n",
        "    #X = torch.tensor([inp])\n",
        "    #out.append(qmodel(X).detach().numpy().reshape([64]).tolist())\n",
        "\n",
        "#sb.heatmap(out,cmap= sb.color_palette(\"coolwarm\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "xleRvQZyBN-J"
      },
      "outputs": [],
      "source": [
        "#for i in qmodel.named_parameters():\n",
        "    #print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZdapHwbBN-J"
      },
      "source": [
        "# Declaring Hybrid Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "1b19506f-33c6-4b57-ba82-ea51a7854825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding_layer): HybridModel(\n",
            "    (inpFormat): Linear(in_features=16, out_features=8, bias=True)\n",
            "    (qlayer_1): <Quantum Torch Layer: func=qnode>\n",
            "    (qlayer_2): <Quantum Torch Layer: func=qnode>\n",
            "    (clayer): Linear(in_features=8, out_features=64, bias=True)\n",
            "  )\n",
            "  (rnn): RNN(64, 32, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = HybridModel(64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "#model = RNN()\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwL98-FwEWsu",
        "outputId": "265a4370-c33b-4517-9f03-a1b0eb90a265"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSekXgzPBN-K",
        "outputId": "795b6e7a-fde4-47cd-c877-fcd851679f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Linear(in_features=16, out_features=8, bias=True)                                     2                 2                    136                                     \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    4                                       \n",
            "<Quantum Torch Layer: func=qnode>                                                     1                 1                    4                                       \n",
            "Linear(in_features=8, out_features=64, bias=True)                                     2                 2                    576                                     \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 9,202\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "9202"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from word2ket import EmbeddingKet, EmbeddingKetXS , ketify,summary\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.017, momentum=0.9)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ClGhRFaJBN-M"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "848e5eb8-b38d-42fc-f1f3-970fd74058d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|          | 0/96 [00:00<?, ?batch/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:  15%|█▍        | 14/96 [3:51:05<22:33:29, 990.36s/batch, loss=0.733]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[56], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     10\u001b[0m   optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 11\u001b[0m   output \u001b[39m=\u001b[39m model(text)\n\u001b[0;32m     12\u001b[0m   loss \u001b[39m=\u001b[39m criterion(output, tgt)\n\u001b[0;32m     13\u001b[0m   loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[52], line 12\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, X_batch)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, X_batch):\n\u001b[1;32m---> 12\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_layer(X_batch)\n\u001b[0;32m     13\u001b[0m     output, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn(embeddings)\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact(output[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])))))\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[47], line 49\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39m=\u001b[39m {}\n\u001b[0;32m     48\u001b[0m \u001b[39mif\u001b[39;00m  x\u001b[39m.\u001b[39mdim()\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__EmbeddingBag__(x)\n\u001b[1;32m---> 49\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(x)\n",
            "Cell \u001b[1;32mIn[47], line 42\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n\u001b[1;32m---> 42\u001b[0m     Bag\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(subtensor))\n\u001b[0;32m     43\u001b[0m \u001b[39m#print(Bag)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(Bag)\n",
            "Cell \u001b[1;32mIn[47], line 42\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     40\u001b[0m Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n\u001b[1;32m---> 42\u001b[0m     Bag\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__RecursiveBag__(subtensor))\n\u001b[0;32m     43\u001b[0m \u001b[39m#print(Bag)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(Bag)\n",
            "Cell \u001b[1;32mIn[47], line 38\u001b[0m, in \u001b[0;36mHybridModel.__RecursiveBag__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__RecursiveBag__\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[0;32m     37\u001b[0m     \u001b[39m#print(x.dim())\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdim()\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__EmbeddingBag__(x)\n\u001b[0;32m     40\u001b[0m     Bag \u001b[39m=\u001b[39m []\n\u001b[0;32m     41\u001b[0m     \u001b[39mfor\u001b[39;00m subtensor \u001b[39min\u001b[39;00m x:\n",
            "Cell \u001b[1;32mIn[47], line 24\u001b[0m, in \u001b[0;36mHybridModel.__EmbeddingBag__\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minpFormat(x\u001b[39m.\u001b[39mfloat())\n\u001b[0;32m     23\u001b[0m \u001b[39m#Split Layer into 2 seperate Quantum Circuits\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m x_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqlayer_1(x[:n_qubits\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m     25\u001b[0m x_2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqlayer_2(x[n_qubits :])\n\u001b[0;32m     28\u001b[0m \u001b[39m#Concatnate and Resize output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnn\\torch.py:402\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    399\u001b[0m     inputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mreshape(inputs, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, inputs\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]))\n\u001b[0;32m    401\u001b[0m \u001b[39m# calculate the forward pass as usual\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_qnode(inputs)\n\u001b[0;32m    404\u001b[0m \u001b[39m# reshape to the correct number of batch dims\u001b[39;00m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m has_batch_dim:\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnn\\torch.py:423\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    412\u001b[0m \n\u001b[0;32m    413\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    419\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    420\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_arg: x},\n\u001b[0;32m    421\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{arg: weight\u001b[39m.\u001b[39mto(x) \u001b[39mfor\u001b[39;00m arg, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnode_weights\u001b[39m.\u001b[39mitems()},\n\u001b[0;32m    422\u001b[0m }\n\u001b[1;32m--> 423\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    425\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    426\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\qnode.py:1039\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1034\u001b[0m         full_transform_program\u001b[39m.\u001b[39m_set_all_argnums(\n\u001b[0;32m   1035\u001b[0m             \u001b[39mself\u001b[39m, args, kwargs, argnums\n\u001b[0;32m   1036\u001b[0m         )  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1040\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,),\n\u001b[0;32m   1041\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[0;32m   1042\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[0;32m   1043\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[0;32m   1044\u001b[0m     transform_program\u001b[39m=\u001b[39;49mfull_transform_program,\n\u001b[0;32m   1045\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m   1046\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[0;32m   1047\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[0;32m   1048\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[0;32m   1049\u001b[0m )\n\u001b[0;32m   1051\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1053\u001b[0m \u001b[39m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:648\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform, device_vjp)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[39m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[39mif\u001b[39;00m no_interface_boundary_required:\n\u001b[1;32m--> 648\u001b[0m     results \u001b[39m=\u001b[39m inner_execute(tapes)\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m post_processing(results)\n\u001b[0;32m    651\u001b[0m _grad_on_execution \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:261\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mif\u001b[39;00m numpy_only:\n\u001b[0;32m    260\u001b[0m     tapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(qml\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tapes)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mreturn\u001b[39;00m cached_device_execution(tapes)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:383\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[0;32m    380\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[39m# convert to list as new device interface returns a tuple\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(fn(\u001b[39mtuple\u001b[39;49m(execution_tapes\u001b[39m.\u001b[39;49mvalues()), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m    385\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[0;32m    387\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:523\u001b[0m, in \u001b[0;36mDefaultQubit.execute\u001b[1;34m(self, circuits, execution_config)\u001b[0m\n\u001b[0;32m    517\u001b[0m interface \u001b[39m=\u001b[39m (\n\u001b[0;32m    518\u001b[0m     execution_config\u001b[39m.\u001b[39minterface\n\u001b[0;32m    519\u001b[0m     \u001b[39mif\u001b[39;00m execution_config\u001b[39m.\u001b[39mgradient_method \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    520\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m max_workers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 523\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    524\u001b[0m         simulate(\n\u001b[0;32m    525\u001b[0m             c,\n\u001b[0;32m    526\u001b[0m             rng\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rng,\n\u001b[0;32m    527\u001b[0m             prng_key\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prng_key,\n\u001b[0;32m    528\u001b[0m             debugger\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debugger,\n\u001b[0;32m    529\u001b[0m             interface\u001b[39m=\u001b[39minterface,\n\u001b[0;32m    530\u001b[0m             state_cache\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state_cache,\n\u001b[0;32m    531\u001b[0m         )\n\u001b[0;32m    532\u001b[0m         \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     vanilla_circuits \u001b[39m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits]\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\default_qubit.py:524\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    517\u001b[0m interface \u001b[39m=\u001b[39m (\n\u001b[0;32m    518\u001b[0m     execution_config\u001b[39m.\u001b[39minterface\n\u001b[0;32m    519\u001b[0m     \u001b[39mif\u001b[39;00m execution_config\u001b[39m.\u001b[39mgradient_method \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m}\n\u001b[0;32m    520\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m max_workers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m--> 524\u001b[0m         simulate(\n\u001b[0;32m    525\u001b[0m             c,\n\u001b[0;32m    526\u001b[0m             rng\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rng,\n\u001b[0;32m    527\u001b[0m             prng_key\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prng_key,\n\u001b[0;32m    528\u001b[0m             debugger\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_debugger,\n\u001b[0;32m    529\u001b[0m             interface\u001b[39m=\u001b[39;49minterface,\n\u001b[0;32m    530\u001b[0m             state_cache\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state_cache,\n\u001b[0;32m    531\u001b[0m         )\n\u001b[0;32m    532\u001b[0m         \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits\n\u001b[0;32m    533\u001b[0m     )\n\u001b[0;32m    534\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    535\u001b[0m     vanilla_circuits \u001b[39m=\u001b[39m [convert_to_numpy_parameters(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m circuits]\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:243\u001b[0m, in \u001b[0;36msimulate\u001b[1;34m(circuit, rng, prng_key, debugger, interface, state_cache)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m state_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     state_cache[circuit\u001b[39m.\u001b[39mhash] \u001b[39m=\u001b[39m state\n\u001b[1;32m--> 243\u001b[0m \u001b[39mreturn\u001b[39;00m measure_final_state(circuit, state, is_state_batched, rng\u001b[39m=\u001b[39;49mrng, prng_key\u001b[39m=\u001b[39;49mprng_key)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:177\u001b[0m, in \u001b[0;36mmeasure_final_state\u001b[1;34m(circuit, state, is_state_batched, rng, prng_key)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(circuit\u001b[39m.\u001b[39mmeasurements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    175\u001b[0m         \u001b[39mreturn\u001b[39;00m measure(circuit\u001b[39m.\u001b[39mmeasurements[\u001b[39m0\u001b[39m], state, is_state_batched\u001b[39m=\u001b[39mis_state_batched)\n\u001b[1;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[0;32m    178\u001b[0m         measure(mp, state, is_state_batched\u001b[39m=\u001b[39mis_state_batched) \u001b[39mfor\u001b[39;00m mp \u001b[39min\u001b[39;00m circuit\u001b[39m.\u001b[39mmeasurements\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[39m# finite-shot case\u001b[39;00m\n\u001b[0;32m    183\u001b[0m rng \u001b[39m=\u001b[39m default_rng(rng)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\simulate.py:178\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(circuit\u001b[39m.\u001b[39mmeasurements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    175\u001b[0m         \u001b[39mreturn\u001b[39;00m measure(circuit\u001b[39m.\u001b[39mmeasurements[\u001b[39m0\u001b[39m], state, is_state_batched\u001b[39m=\u001b[39mis_state_batched)\n\u001b[0;32m    177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m--> 178\u001b[0m         measure(mp, state, is_state_batched\u001b[39m=\u001b[39;49mis_state_batched) \u001b[39mfor\u001b[39;00m mp \u001b[39min\u001b[39;00m circuit\u001b[39m.\u001b[39mmeasurements\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[39m# finite-shot case\u001b[39;00m\n\u001b[0;32m    183\u001b[0m rng \u001b[39m=\u001b[39m default_rng(rng)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\measure.py:234\u001b[0m, in \u001b[0;36mmeasure\u001b[1;34m(measurementprocess, state, is_state_batched)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure\u001b[39m(\n\u001b[0;32m    222\u001b[0m     measurementprocess: MeasurementProcess, state: TensorLike, is_state_batched: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    223\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m TensorLike:\n\u001b[0;32m    224\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Apply a measurement process to a state.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m        Tensorlike: the result of the measurement\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m get_measurement_function(measurementprocess, state)(\n\u001b[0;32m    235\u001b[0m         measurementprocess, state, is_state_batched\n\u001b[0;32m    236\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\devices\\qubit\\measure.py:72\u001b[0m, in \u001b[0;36mstate_diagonalizing_gates\u001b[1;34m(measurementprocess, state, is_state_batched)\u001b[0m\n\u001b[0;32m     70\u001b[0m wires \u001b[39m=\u001b[39m Wires(\u001b[39mrange\u001b[39m(total_indices))\n\u001b[0;32m     71\u001b[0m flattened_state \u001b[39m=\u001b[39m flatten_state(state, total_indices)\n\u001b[1;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m measurementprocess\u001b[39m.\u001b[39;49mprocess_state(flattened_state, wires)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\measurements\\expval.py:130\u001b[0m, in \u001b[0;36mExpectationMP.process_state\u001b[1;34m(self, state, wire_order)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m# we use ``self.wires`` instead of ``self.obs`` because the observable was\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m# already applied to the state\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39mwith\u001b[39;00m qml\u001b[39m.\u001b[39mqueuing\u001b[39m.\u001b[39mQueuingManager\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m--> 130\u001b[0m     prob \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mprobs(wires\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwires)\u001b[39m.\u001b[39;49mprocess_state(state\u001b[39m=\u001b[39;49mstate, wire_order\u001b[39m=\u001b[39;49mwire_order)\n\u001b[0;32m    131\u001b[0m \u001b[39m# In case of broadcasting, `prob` has two axes and this is a matrix-vector product\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39mreturn\u001b[39;00m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mdot(prob, eigvals)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pennylane\\measurements\\probs.py:209\u001b[0m, in \u001b[0;36mProbabilityMP.process_state\u001b[1;34m(self, state, wire_order)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_state\u001b[39m(\u001b[39mself\u001b[39m, state: Sequence[\u001b[39mcomplex\u001b[39m], wire_order: Wires):\n\u001b[1;32m--> 209\u001b[0m     prob \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreal(state) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m+\u001b[39m qml\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mimag(state) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    210\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwires \u001b[39m==\u001b[39m Wires([]):\n\u001b[0;32m    211\u001b[0m         \u001b[39m# no need to marginalize\u001b[39;00m\n\u001b[0;32m    212\u001b[0m         \u001b[39mreturn\u001b[39;00m prob\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autoray\\autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[39mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m backend \u001b[39m=\u001b[39m choose_backend(fn, \u001b[39m*\u001b[39margs, like\u001b[39m=\u001b[39mlike, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m---> 80\u001b[0m \u001b[39mreturn\u001b[39;00m get_lib_fn(backend, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\autoray\\autoray.py:1880\u001b[0m, in \u001b[0;36mtorch_imag\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1878\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1879\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mis_complex():\n\u001b[1;32m-> 1880\u001b[0m         \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39;49mimag\n\u001b[0;32m   1881\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m   1882\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\fx\\traceback.py:68\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m [current_meta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstack_trace\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)]\n\u001b[0;32m     66\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[39m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[39mreturn\u001b[39;00m traceback\u001b[39m.\u001b[39mformat_list(traceback\u001b[39m.\u001b[39;49mextract_stack()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:231\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 231\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[0;32m    232\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:393\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[39mfor\u001b[39;00m f, lineno \u001b[39min\u001b[39;00m frame_gen:\n\u001b[0;32m    391\u001b[0m         \u001b[39myield\u001b[39;00m f, (lineno, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 393\u001b[0m \u001b[39mreturn\u001b[39;00m klass\u001b[39m.\u001b[39;49m_extract_from_extended_frame_gen(\n\u001b[0;32m    394\u001b[0m     extended_frame_gen(), limit\u001b[39m=\u001b[39;49mlimit, lookup_lines\u001b[39m=\u001b[39;49mlookup_lines,\n\u001b[0;32m    395\u001b[0m     capture_locals\u001b[39m=\u001b[39;49mcapture_locals)\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\traceback.py:432\u001b[0m, in \u001b[0;36mStackSummary._extract_from_extended_frame_gen\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    428\u001b[0m     result\u001b[39m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    429\u001b[0m         filename, lineno, name, lookup_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39mlocals\u001b[39m\u001b[39m=\u001b[39mf_locals,\n\u001b[0;32m    430\u001b[0m         end_lineno\u001b[39m=\u001b[39mend_lineno, colno\u001b[39m=\u001b[39mcolno, end_colno\u001b[39m=\u001b[39mend_colno))\n\u001b[0;32m    431\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m fnames:\n\u001b[1;32m--> 432\u001b[0m     linecache\u001b[39m.\u001b[39;49mcheckcache(filename)\n\u001b[0;32m    433\u001b[0m \u001b[39m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n",
            "File \u001b[1;32mc:\\Users\\shado\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[39mcontinue\u001b[39;00m   \u001b[39m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstat(fullname)\n\u001b[0;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[39m.\u001b[39mpop(filename, \u001b[39mNone\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "accuracy = []\n",
        "epochs = 1\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    with tqdm.tqdm(train_loader , unit = \"batch\") as tepoch:\n",
        "      for text, tgt in tepoch:\n",
        "        tepoch.set_description(f\"Epoch {e}\")\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "          optimizer.zero_grad()\n",
        "          output = model.embedding_layer(text)\n",
        "          loss = criterion(output, tgt)\n",
        "          loss.backward(retain_graph=True)\n",
        "\n",
        "        optimizer.step()\n",
        "        tepoch.set_postfix(loss=loss.item())\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "      else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "\n",
        "\n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "    #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n",
        "    accuracy.append((correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
