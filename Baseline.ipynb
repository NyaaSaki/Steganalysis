{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5 Text Clasification\n",
        "\n",
        "Roshan Ahmed\n",
        "20BRS1072"
      ],
      "metadata": {
        "id": "F5e7olJcsGkZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-w9jq2Uqd8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7f00c6-0fba-415c-e8ae-b024f4200dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 15:58:29--  https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 502 Bad Gateway\n",
            "2023-06-07 15:58:30 ERROR 502: Bad Gateway.\n",
            "\n",
            "Archive:  /content/smsspamcollection.zip\n",
            "replace SMSSpamCollection? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "!unzip /content/smsspamcollection.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "d-EeHbxXy_jH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ],
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/SMSSpamCollection\",delimiter = \"\t\",names = [\"sh\",\"text\"])\n",
        "\n",
        "data['label'] = z\n",
        "data = data.drop('sh',axis = 1)\n",
        "print(data)\n",
        "data.to_csv(\"messages.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "bb3f74ca-10aa-4215-8501-4a297fbc01cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "0     Go until jurong point, crazy.. Available only ...      0\n",
            "1                         Ok lar... Joking wif u oni...      0\n",
            "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
            "3     U dun say so early hor... U c already then say...      0\n",
            "4     Nah I don't think he goes to usf, he lives aro...      0\n",
            "...                                                 ...    ...\n",
            "5567  This is the 2nd time we have tried 2 contact u...      1\n",
            "5568               Will Ã¼ b going to esplanade fr home?      0\n",
            "5569  Pity, * was in mood for that. So...any other s...      0\n",
            "5570  The guy did some bitching but I acted like i'd...      0\n",
            "5571                         Rofl. Its true to its name      0\n",
            "\n",
            "[5572 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upsampling minority class"
      ],
      "metadata": {
        "id": "c-Eh015g750h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spam = data[data.label==1]\n",
        "\n",
        "data = pd.concat([data,spam,spam,spam,spam])\n",
        "\n",
        "print(data)\n",
        "print( data[data.label==1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9--XPow7VXZ",
        "outputId": "d166324f-bc24-480c-ccfb-8b7481a9917d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "0     Go until jurong point, crazy.. Available only ...      0\n",
            "1                         Ok lar... Joking wif u oni...      0\n",
            "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
            "3     U dun say so early hor... U c already then say...      0\n",
            "4     Nah I don't think he goes to usf, he lives aro...      0\n",
            "...                                                 ...    ...\n",
            "5537  Want explicit SEX in 30 secs? Ring 02073162414...      1\n",
            "5540  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...      1\n",
            "5547  Had your contract mobile 11 Mnths? Latest Moto...      1\n",
            "5566  REMINDER FROM O2: To get 2.50 pounds free call...      1\n",
            "5567  This is the 2nd time we have tried 2 contact u...      1\n",
            "\n",
            "[8560 rows x 2 columns]\n",
            "                                                   text  label\n",
            "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
            "5     FreeMsg Hey there darling it's been 3 week's n...      1\n",
            "8     WINNER!! As a valued network customer you have...      1\n",
            "9     Had your mobile 11 months or more? U R entitle...      1\n",
            "11    SIX chances to win CASH! From 100 to 20,000 po...      1\n",
            "...                                                 ...    ...\n",
            "5537  Want explicit SEX in 30 secs? Ring 02073162414...      1\n",
            "5540  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...      1\n",
            "5547  Had your contract mobile 11 Mnths? Latest Moto...      1\n",
            "5566  REMINDER FROM O2: To get 2.50 pounds free call...      1\n",
            "5567  This is the 2nd time we have tried 2 contact u...      1\n",
            "\n",
            "[3735 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating tokenizer and vocabulary"
      ],
      "metadata": {
        "id": "2-sTY6w8sPBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=1, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ],
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dataloader"
      ],
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>50:\n",
        "      return seq[:50]\n",
        "    else:\n",
        "      for i in range(50-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['label'])\n",
        "  def __getitem__(self,idx):\n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , self.df['label'][idx]\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()) , batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()) , batch_size=64)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "0c39e30a-52dd-42b0-9924-b513b5a55397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test)\n",
        "print(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "8378145f-943c-440c-b1a6-e6bc4ad80aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  label\n",
            "4599  I'm stuck in da middle of da row on da right h...      0\n",
            "4008                        I'm reaching home in 5 min.      0\n",
            "1475  Friendship is not a game to play, It is not a ...      0\n",
            "3844  Yes ammae....life takes lot of turns you can o...      0\n",
            "4536                      IM LATE TELLMISS IM ON MY WAY      0\n",
            "...                                                 ...    ...\n",
            "305   SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...      1\n",
            "333   Call Germany for only 1 pence per minute! Call...      1\n",
            "132             Dear, will call Tmorrow.pls accomodate.      0\n",
            "1350  FREE2DAY sexy St George's Day pic of Jordan!Tx...      1\n",
            "3377  Good afternon, my love. How are today? I hope ...      0\n",
            "\n",
            "[1712 rows x 2 columns]\n",
            "                                                   text  label\n",
            "4754  Cashbin.co.uk (Get lots of cash this weekend!)...      1\n",
            "1322  I wake up long ago already... Dunno, what othe...      0\n",
            "334   Any chance you might have had with me evaporat...      0\n",
            "1374  Bears Pic Nick, and Tom, Pete and ... Dick. In...      1\n",
            "1632  We not watching movie already. Xy wants 2 shop...      0\n",
            "...                                                 ...    ...\n",
            "1793  WIN: We have a winner! Mr. T. Foley won an iPo...      1\n",
            "225   500 New Mobiles from 2004, MUST GO! Txt: NOKIA...      1\n",
            "897   Hope you are having a good week. Just checking in      0\n",
            "3547  SO IS TH GOWER MATE WHICH IS WHERE I AM!?! HOW...      0\n",
            "378   Well there's not a lot of things happening in ...      0\n",
            "\n",
            "[6848 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating RNN"
      ],
      "metadata": {
        "id": "sBASklq2sVY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(len(vocab),32)\n",
        "        self.rnn = nn.RNN(32,16, 4, batch_first=True)\n",
        "        self.linear1 = nn.Linear(16,8)\n",
        "        self.linear2 = nn.Linear(8,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "model = RNN()\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "c8bc3725-3f1c-440d-84c9-0a194fd89e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (embedding_layer): Embedding(9198, 32)\n",
            "  (rnn): RNN(32, 16, num_layers=4, batch_first=True)\n",
            "  (linear1): Linear(in_features=16, out_features=8, bias=True)\n",
            "  (linear2): Linear(in_features=8, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.007, momentum=0.90)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ],
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "NUNFSJmNsXd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for text, tgt in train_loader:\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "  #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "ea4031a7-e6ef-4e62-f9df-1f82601c52f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 - Training loss: 0.17151256782986293\n",
            "Model Accuracy = 0.5817757009345794\n",
            "\n",
            "Epoch 2 - Training loss: 0.16969944007485827\n",
            "Model Accuracy = 0.5811915887850467\n",
            "\n",
            "Epoch 3 - Training loss: 0.16401223643360852\n",
            "Model Accuracy = 0.7009345794392523\n",
            "\n",
            "Epoch 4 - Training loss: 0.13987906367700792\n",
            "Model Accuracy = 0.834696261682243\n",
            "\n",
            "Epoch 5 - Training loss: 0.0921846120574764\n",
            "Model Accuracy = 0.852803738317757\n",
            "\n",
            "Epoch 6 - Training loss: 0.07627979702551231\n",
            "Model Accuracy = 0.9018691588785047\n",
            "\n",
            "Epoch 7 - Training loss: 0.06716198218272668\n",
            "Model Accuracy = 0.9065420560747663\n",
            "\n",
            "Epoch 8 - Training loss: 0.06011618886177785\n",
            "Model Accuracy = 0.9065420560747663\n",
            "\n",
            "Epoch 9 - Training loss: 0.0540617302791259\n",
            "Model Accuracy = 0.9182242990654206\n",
            "\n",
            "Epoch 10 - Training loss: 0.044291950535969196\n",
            "Model Accuracy = 0.9404205607476636\n",
            "\n",
            "Epoch 11 - Training loss: 0.03954624881637152\n",
            "Model Accuracy = 0.9246495327102804\n",
            "\n",
            "Epoch 12 - Training loss: 0.034245613087664974\n",
            "Model Accuracy = 0.9415887850467289\n",
            "\n",
            "Epoch 13 - Training loss: 0.033330899145384535\n",
            "Model Accuracy = 0.9532710280373832\n",
            "\n",
            "Epoch 14 - Training loss: 0.02839827584755546\n",
            "Model Accuracy = 0.9415887850467289\n",
            "\n",
            "Epoch 15 - Training loss: 0.028194365931552983\n",
            "Model Accuracy = 0.9322429906542056\n",
            "\n",
            "Epoch 16 - Training loss: 0.02515182572974014\n",
            "Model Accuracy = 0.9579439252336449\n",
            "\n",
            "Epoch 17 - Training loss: 0.024250281589523515\n",
            "Model Accuracy = 0.8738317757009346\n",
            "\n",
            "Epoch 18 - Training loss: 0.026900588909042216\n",
            "Model Accuracy = 0.9684579439252337\n",
            "\n",
            "Epoch 19 - Training loss: 0.01659564296149205\n",
            "Model Accuracy = 0.9690420560747663\n",
            "\n",
            "Epoch 20 - Training loss: 0.015239959974364142\n",
            "Model Accuracy = 0.9550233644859814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ],
      "metadata": {
        "id": "aZAXL3oV02zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = input()\n",
        "tokens = tokenizer(test)\n",
        "indexes = vocab(tokens)\n",
        "logps = model(torch.tensor(indexes).view(1,-1))\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.detach().numpy()[0])\n",
        "pred_label = probab.index(max(probab))\n",
        "if pred_label == 0:\n",
        "  print(\"normal\")\n",
        "else:\n",
        "  print(\"spam\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYJX1fz402S3",
        "outputId": "3fcd78b1-3c9c-40f0-dbdc-c687a28a2127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
            "spam\n"
          ]
        }
      ]
    }
  ]
}