{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5e7olJcsGkZ"
      },
      "source": [
        "# Lab 5 Text Clasification\n",
        "\n",
        "Roshan Ahmed\n",
        "20BRS1072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "6e7f00c6-0fba-415c-e8ae-b024f4200dc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchtext in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (0.16.1)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (2.28.1)\n",
            "Requirement already satisfied: torchdata==0.7.1 in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: torch==2.1.1 in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (from torchtext) (2.1.1)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (2022.11.0)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (3.9.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (2.8.4)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (4.4.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchdata==0.7.1->torchtext) (1.26.14)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.1->torchtext) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.1->torchtext) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "bb3f74ca-10aa-4215-8501-4a297fbc01cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "0c39e30a-52dd-42b0-9924-b513b5a55397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "    \n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()) , batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()) , batch_size=128)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "8378145f-943c-440c-b1a6-e6bc4ad80aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "4753        4753  I rise and vanish in oblivious host. What cand...     True\n",
            "4012        4012  human eyes like the planet And despair. Made. ...     True\n",
            "2334        2334  When summer ended the leaves of snapdragons wi...    False\n",
            "598          598  Just tell me who the hell am I? What powers di...    False\n",
            "1237        1237  tides. Coffee would be less dependent on other...     True\n",
            "...          ...                                                ...      ...\n",
            "3075        3075  thick in whiskey in every evening she had bumm...     True\n",
            "1680        1680  Some may have blamed you that you took away Th...    False\n",
            "4000        4000  shoot. I hear the spirits. What who do you nee...     True\n",
            "21            21  you find in the chute. It was their time s sha...     True\n",
            "398          398  I was ill, lying on my bed of old papers, when...    False\n",
            "\n",
            "[959 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "2957        2957  simmered in a drawer she can ill afford the ad...     True\n",
            "989          989  swimming pools or lilies when you had no wings...     True\n",
            "250          250  To make beauty out of pain, it damns the eyes—...    False\n",
            "1508        1508  thoughtI cannot die But still kept its inner o...     True\n",
            "2038        2038  back into the desert soon shall sweep. As he w...     True\n",
            "...          ...                                                ...      ...\n",
            "3140        3140  The town’s trees, roomy with winter, have begu...    False\n",
            "4377        4377  pointing at his legs are as if some Souls for ...     True\n",
            "1724        1724  It was so simple: you came back to me And I wa...    False\n",
            "1050        1050  I dreamed I dwelled in a homeless place Where ...    False\n",
            "3776        3776  More than no more. The man a boy dozed at my e...     True\n",
            "\n",
            "[3835 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "Creating RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "c8bc3725-3f1c-440d-84c9-0a194fd89e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding_layer): Embedding(18658, 64)\n",
            "  (rnn): RNN(64, 32, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(len(vocab),64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "model = RNN()\n",
        "\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Embedding(18658, 64)                                                                  1                 1                    1,194,112                               \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 1,202,594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1202594"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from word2ket import EmbeddingKet, EmbeddingKetXS , ketify,summary\n",
        "summary(model)\n",
        "#ketify(model,order = 4,rank = 2, use_EmbeddingKetXS= False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Module Name                                                                           Total Parameters  Trainable Parameters # Elements in Trainable Parametrs       \n",
            "Embedding(18658, 64)                                                                  1                 1                    1,194,112                               \n",
            "RNN(64, 32, num_layers=3, batch_first=True)                                           12                12                   7,360                                   \n",
            "Linear(in_features=32, out_features=32, bias=True)                                    2                 2                    1,056                                   \n",
            "Linear(in_features=32, out_features=2, bias=True)                                     2                 2                    66                                      \n",
            "ReLU()                                                                                0                 0                    0                                       \n",
            "LogSoftmax(dim=1)                                                                     0                 0                    0                                       \n",
            "Total number of trainable parameters elements 1,202,594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1202594"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.5)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "ea4031a7-e6ef-4e62-f9df-1f82601c52f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 - Training loss: 0.0861392229795456\n",
            "Model Accuracy = 0.5891553701772679\n",
            "\n",
            "Epoch 2 - Training loss: 0.0847354955971241\n",
            "Model Accuracy = 0.670490093847758\n",
            "\n",
            "Epoch 3 - Training loss: 0.08300437852740288\n",
            "Model Accuracy = 0.7153284671532847\n",
            "\n",
            "Epoch 4 - Training loss: 0.08057938714822134\n",
            "Model Accuracy = 0.7476538060479666\n",
            "\n",
            "Epoch 5 - Training loss: 0.07747615948319435\n",
            "Model Accuracy = 0.7528675703858185\n",
            "\n",
            "Epoch 6 - Training loss: 0.07431974609692892\n",
            "Model Accuracy = 0.7570385818561001\n",
            "\n",
            "Epoch 7 - Training loss: 0.07176782712340354\n",
            "Model Accuracy = 0.7612095933263816\n",
            "\n",
            "Epoch 8 - Training loss: 0.06982383628686269\n",
            "Model Accuracy = 0.7601668404588112\n",
            "\n",
            "Epoch 9 - Training loss: 0.06785958160956701\n",
            "Model Accuracy = 0.7643378519290928\n",
            "\n",
            "Epoch 10 - Training loss: 0.06488805624345938\n",
            "Model Accuracy = 0.786235662148071\n",
            "\n",
            "Epoch 11 - Training loss: 0.05919656530022621\n",
            "Model Accuracy = 0.8175182481751825\n",
            "\n",
            "Epoch 12 - Training loss: 0.05389504320919514\n",
            "Model Accuracy = 0.49009384775808135\n",
            "\n",
            "Epoch 13 - Training loss: 0.07438026567300161\n",
            "Model Accuracy = 0.762252346193952\n",
            "\n",
            "Epoch 14 - Training loss: 0.07030695602297783\n",
            "Model Accuracy = 0.7716371220020855\n",
            "\n",
            "Epoch 15 - Training loss: 0.06886028684675694\n",
            "Model Accuracy = 0.7747653806047967\n",
            "\n",
            "Epoch 16 - Training loss: 0.06765373423695564\n",
            "Model Accuracy = 0.7799791449426486\n",
            "\n",
            "Epoch 17 - Training loss: 0.06628766159216563\n",
            "Model Accuracy = 0.7841501564129302\n",
            "\n",
            "Epoch 18 - Training loss: 0.06447124493618807\n",
            "Model Accuracy = 0.7893639207507821\n",
            "\n",
            "Epoch 19 - Training loss: 0.061137265215317406\n",
            "Model Accuracy = 0.7987486965589156\n",
            "\n",
            "Epoch 20 - Training loss: 0.05673014298081398\n",
            "Model Accuracy = 0.848800834202294\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for text, tgt in train_loader:\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "  #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
