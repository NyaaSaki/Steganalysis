{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5e7olJcsGkZ"
      },
      "source": [
        "# Lab 5 Text Clasification\n",
        "\n",
        "Roshan Ahmed\n",
        "20BRS1072"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-w9jq2Uqd8y",
        "outputId": "6e7f00c6-0fba-415c-e8ae-b024f4200dc3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EeHbxXy_jH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qRT8AT3Wy_Gw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torchtext in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (0.16.1)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (2.28.1)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (4.64.1)\n",
            "Requirement already satisfied: torch==2.1.1 in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (from torchtext) (2.1.1)\n",
            "Requirement already satisfied: torchdata==0.7.1 in c:\\users\\shado\\appdata\\roaming\\python\\python310\\site-packages (from torchtext) (0.7.1)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (1.23.5)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (3.9.0)\n",
            "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (2.8.4)\n",
            "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (4.4.0)\n",
            "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (2022.11.0)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.1.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchdata==0.7.1->torchtext) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchtext) (2.0.4)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->torchtext) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.1.1->torchtext) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch==2.1.1->torchtext) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "import torchtext\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjC37RPGzF8G",
        "outputId": "bb3f74ca-10aa-4215-8501-4a297fbc01cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "0              0  The soil I’m walking over comes    from deeper...    False\n",
            "1              1  the close air of the earth whence she derived ...     True\n",
            "2              2  Lyric night of the lingering Indian Summer,\\nS...    False\n",
            "3              3  “Percussus sum sicut foenum, et aruit cor meum...    False\n",
            "4              4  I should be happy with my lot: A wife and moth...    False\n",
            "...          ...                                                ...      ...\n",
            "4789        4789  office has never really is its oldest daughter...     True\n",
            "4790        4790  soot from her car with suitcases and hugged he...     True\n",
            "4791        4791  Seeing in crowded restaurants the one you love...    False\n",
            "4792        4792  flower sweet as I can never forsake And Fortun...     True\n",
            "4793        4793  Echo that loved hid within a wood Would to her...    False\n",
            "\n",
            "[4794 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"dataframe.csv\")\n",
        "print(data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-sTY6w8sPBX"
      },
      "source": [
        "Creating tokenizer and vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MDqO8gKlr_8-"
      },
      "outputs": [],
      "source": [
        "from torchtext.data import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils import rnn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def build_vocabulary(datasets):\n",
        "    for dataset in datasets:\n",
        "        #print(dataset)\n",
        "        for text in dataset['text']:\n",
        "            yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(build_vocabulary([data,data]), min_freq=3, specials=[\"<UNK>\"])\n",
        "\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "\n",
        "for l in data['text']:\n",
        "  tokens = tokenizer(l)\n",
        "  indexes = vocab(tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N3ERPfXsS5Y"
      },
      "source": [
        "Creating Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lCTwLmc3qbY",
        "outputId": "0c39e30a-52dd-42b0-9924-b513b5a55397"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class Text(Dataset):\n",
        "  def __init__(self,df):\n",
        "    self.df = df\n",
        "    #print(df)\n",
        "\n",
        "  def pad(self,seq):\n",
        "    if len(seq)>140:\n",
        "      return seq[:140]\n",
        "    else:\n",
        "      for i in range(140-len(seq)):\n",
        "        seq.insert(0,0)\n",
        "      return seq\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df['encoded'])\n",
        "  def __getitem__(self,idx):\n",
        "    \n",
        "    return torch.tensor(self.pad(vocab(tokenizer(self.df['text'][idx])))) , int(self.df['encoded'][idx])\n",
        "\n",
        "test_loader  = DataLoader(Text(test.reset_index()) , batch_size=4)\n",
        "train_loader = DataLoader(Text(train.reset_index()) , batch_size=128)\n",
        "\n",
        "for txt , tgt in test_loader:\n",
        "  _\n",
        "  #print(txt)\n",
        "  #print(txt)\n",
        "voc = len(vocab)\n",
        "#print(tokens)\n",
        "\n",
        "print(vocab([\"<UNK>\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA8yAqD5uNlv",
        "outputId": "8378145f-943c-440c-b1a6-e6bc4ad80aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Unnamed: 0                                               text  encoded\n",
            "3215        3215  farmerhad slammed doors were sweet potato but ...     True\n",
            "3882        3882  to suggest someone had smashed and somehow hea...     True\n",
            "2253        2253  Eat thou and drink; to-morrow thou shalt die. ...    False\n",
            "385          385  O what a strange parcel of creatures are we, S...    False\n",
            "4767        4767  The animals they mistake it that once upon the...     True\n",
            "...          ...                                                ...      ...\n",
            "3772        3772  growing too long. He takes from you. Not the k...     True\n",
            "2916        2916  face. To wither in theyr love. It makes me sad...     True\n",
            "991          991  do not say I thought I d pried too far beneath...     True\n",
            "1307        1307  fright. I keep me alone. It My bad and we live...     True\n",
            "3971        3971  O world, I cannot hold thee close enough!    T...    False\n",
            "\n",
            "[959 rows x 3 columns]\n",
            "      Unnamed: 0                                               text  encoded\n",
            "3293        3293  Is the woman in the pool of light really readi...    False\n",
            "1388        1388  Unraveling velvet, wave after wave, driven  by...    False\n",
            "4703        4703  so I smile to think mankind All hollow. We bre...     True\n",
            "1211        1211  Hell. How far the world above the parking lot....     True\n",
            "3008        3008  thunder melodramaNeither describable nor beara...     True\n",
            "...          ...                                                ...      ...\n",
            "1021        1021  I married in the world’s black night for warmt...    False\n",
            "1434        1434  I can play songs in my head Yes I can perfectl...    False\n",
            "3400        3400  If I am in the house beams posts planks siding...    False\n",
            "2949        2949  Not one alone Into his ken Or like smiling Olm...     True\n",
            "2711        2711  moons Bring me not at night. While neighbors I...     True\n",
            "\n",
            "[3835 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "print(test)\n",
        "print(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBASklq2sVY4"
      },
      "source": [
        "Creating RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lho9HQKX5xQ4",
        "outputId": "c8bc3725-3f1c-440d-84c9-0a194fd89e47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding_layer): Embedding(18658, 64)\n",
            "  (rnn): RNN(64, 32, num_layers=3, batch_first=True)\n",
            "  (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
            "  (linear2): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (act): ReLU()\n",
            "  (out): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(len(vocab),64)\n",
        "        self.rnn = nn.RNN(64,32, 3, batch_first=True)\n",
        "        self.linear1 = nn.Linear(32,32)\n",
        "        self.linear2 = nn.Linear(32,2)\n",
        "        self.act = nn.ReLU()\n",
        "        self.out = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        output, hidden = self.rnn(embeddings)\n",
        "        return self.out(self.linear2(self.act(self.linear1(self.act(output[:,-1])))))\n",
        "\n",
        "model = RNN()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Xm4dx7xel-tW"
      },
      "outputs": [],
      "source": [
        "accuracy = []\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.017, momentum=0.5)\n",
        "criterion = nn.NLLLoss()\n",
        "time0 = time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUNFSJmNsXd4"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFaOLWuCXZr",
        "outputId": "ea4031a7-e6ef-4e62-f9df-1f82601c52f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 - Training loss: 0.04370230163137118\n",
            "Model Accuracy = 0.4859228362877998\n",
            "\n",
            "Epoch 2 - Training loss: 0.043363339950641\n",
            "Model Accuracy = 0.48905109489051096\n",
            "\n",
            "Epoch 3 - Training loss: 0.04311799928545952\n",
            "Model Accuracy = 0.5088633993743483\n",
            "\n",
            "Epoch 4 - Training loss: 0.04290950298309326\n",
            "Model Accuracy = 0.5849843587069864\n",
            "\n",
            "Epoch 5 - Training loss: 0.04270238156119983\n",
            "Model Accuracy = 0.6454640250260688\n",
            "\n",
            "Epoch 6 - Training loss: 0.04247122233112653\n",
            "Model Accuracy = 0.6715328467153284\n",
            "\n",
            "Epoch 7 - Training loss: 0.04219724237918854\n",
            "Model Accuracy = 0.6871741397288843\n",
            "\n",
            "Epoch 8 - Training loss: 0.041855471581220625\n",
            "Model Accuracy = 0.6903023983315955\n",
            "\n",
            "Epoch 9 - Training loss: 0.04141383717457454\n",
            "Model Accuracy = 0.6903023983315955\n",
            "\n",
            "Epoch 10 - Training loss: 0.040864415218432745\n",
            "Model Accuracy = 0.6871741397288843\n",
            "\n",
            "Epoch 11 - Training loss: 0.04022093539436658\n",
            "Model Accuracy = 0.6923879040667362\n",
            "\n",
            "Epoch 12 - Training loss: 0.039495383948087694\n",
            "Model Accuracy = 0.6986444212721585\n",
            "\n",
            "Epoch 13 - Training loss: 0.038699883967638016\n",
            "Model Accuracy = 0.7028154327424401\n",
            "\n",
            "Epoch 14 - Training loss: 0.03785808210571607\n",
            "Model Accuracy = 0.7049009384775808\n",
            "\n",
            "Epoch 15 - Training loss: 0.03700717737277349\n",
            "Model Accuracy = 0.7142857142857143\n",
            "\n",
            "Epoch 16 - Training loss: 0.036185546219348906\n",
            "Model Accuracy = 0.7142857142857143\n",
            "\n",
            "Epoch 17 - Training loss: 0.035419576118389764\n",
            "Model Accuracy = 0.7194994786235662\n",
            "\n",
            "Epoch 18 - Training loss: 0.03470312058925629\n",
            "Model Accuracy = 0.7247132429614181\n",
            "\n",
            "Epoch 19 - Training loss: 0.034005185961723326\n",
            "Model Accuracy = 0.7309697601668405\n",
            "\n",
            "Epoch 20 - Training loss: 0.0332642571379741\n",
            "Model Accuracy = 0.7413972888425443\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for text, tgt in train_loader:\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(text)\n",
        "\n",
        "        loss = criterion(output, tgt)\n",
        "\n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        #print(loss.item())\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "        #print(output)\n",
        "        print(\"\\nEpoch {} - Training loss: {}\".format(e+1, running_loss/len(test_loader)))\n",
        "    correct_count, all_count = 0, 0\n",
        "    for images,labels in test_loader:\n",
        "      for i in range(len(labels)):\n",
        "        img = images[i].view(1,-1)\n",
        "        with torch.no_grad():\n",
        "          logps = model(img)\n",
        "\n",
        "\n",
        "        ps = torch.exp(logps)\n",
        "        probab = list(ps.numpy()[0])\n",
        "        pred_label = probab.index(max(probab))\n",
        "        true_label = labels.numpy()[i]\n",
        "        #print(pred_label)\n",
        "        if(true_label == pred_label):\n",
        "          correct_count += 1\n",
        "        all_count += 1\n",
        "\n",
        "  #print(\"Number Of Images Tested =\", all_count)\n",
        "    print(\"Model Accuracy =\", (correct_count/all_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZAXL3oV02zg"
      },
      "source": [
        "#Texts for testing:\n",
        "\n",
        "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
        "\n",
        "Even my brother is not like to speak with me. They treat me like aids patent.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
